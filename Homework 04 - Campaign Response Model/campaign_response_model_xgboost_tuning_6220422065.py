# -*- coding: utf-8 -*-
"""Campaign Response Model - XGBoost Tuning-6220422065.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a_yjz9VEKWCB4TX92u3j3SCb_QB6l_Ol

# Import Libraries

Suthasinee Pojam 6220422065
"""

!pip install six

from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
from xgboost import plot_importance
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import *

import numpy as np
import pandas as pd
import datetime as dt
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
import seaborn as sns

"""# Read CSV"""

from google.colab import drive
drive.mount("/content/drive")

df_response = pd.read_csv('/content/Retail_Data_Response.csv')
df_transactions = pd.read_csv('/content/Retail_Data_Transactions.csv', parse_dates=['trans_date'])
print("df_response",df_response.shape)
print("df_transactions",df_transactions.shape)
print(df_response.head())
print(df_transactions.head())

"""# EDA"""

df_response.info()

df_transactions.info()

df_response.head(10)

df_transactions.head(10)

print(df_transactions['trans_date'].min())
print(df_transactions['trans_date'].max())

"""## **Data Preparation**"""

campaign_date = dt.datetime(2015,3,17)
df_transactions['recent'] = campaign_date - df_transactions['trans_date']
df_transactions['recent'].astype('timedelta64[D]')
df_transactions['recent'] = df_transactions['recent'] / np.timedelta64(1, 'D')
df_transactions.head(10)

df_rfm = df_transactions.groupby('customer_id').agg({'recent': lambda x:x.min(),                      
                                                     'customer_id': lambda x: len(x),                 
                                                     'tran_amount': lambda x: x.sum()})                       

df_rfm.rename(columns={'recent': 'recency', 
                       'customer_id': 'frequency', 
                       'tran_amount': 'monetary_value'}, inplace=True)
df_rfm = df_rfm.reset_index()
df_rfm.head(10)

df_clv = df_transactions.groupby('customer_id').agg({'recent': lambda x:x.min(),                      
                                                     'customer_id': lambda x: len(x),                 
                                                     'tran_amount': lambda x: x.sum(),                          
                                                     'trans_date': lambda x: (x.max() - x.min()).days})      

df_clv.rename(columns={'recent': 'recency', 
                       'customer_id': 'frequency', 
                       'tran_amount': 'monetary_value',
                       'trans_date' : 'AOU'}, inplace=True)

df_clv['ticket_size'] = df_clv['monetary_value'] / df_clv['frequency']

df_clv = df_clv.reset_index()
df_clv.head(10)

"""# Imbalance Response"""

df_group_response = df_response.groupby('response').agg({'customer_id': lambda x: len(x)}).reset_index()
df_group_response.head()

plt.figure(figsize=(10,8))
x=range(2)
plt.bar(x,df_group_response['customer_id'])
plt.xticks(df_group_response.index)
plt.title('Response Distribution')
plt.xlabel('Convert or Not')
plt.ylabel('Users')
plt.show()

response_rfm = pd.merge(df_response,df_rfm)
response_rfm.head(10)

response_clv = pd.merge(df_response,df_clv)
response_clv.head(10)

"""# Creating train / test """

X_rfm = response_rfm.drop(columns=['response','customer_id'])
y_rfm = response_rfm['response']

X_clv = response_clv.drop(columns=['response','customer_id'])
y_clv = response_clv['response']

X_train_rfm, X_test_rfm, y_train_rfm, y_test_rfm = train_test_split(X_rfm, y_rfm, test_size=0.3, random_state=10)
X_train_clv, X_test_clv, y_train_clv, y_test_clv = train_test_split(X_clv, y_clv, test_size=0.3, random_state=10)

"""# Visualization"""

fig, axes = plt.subplots(1,3, figsize=(15, 8), sharex=True)
col =0
for i, col_i in enumerate(response_rfm[['recency', 'frequency', 'monetary_value']].columns):
  for j, col_j in enumerate(response_rfm[['recency', 'frequency', 'monetary_value']].columns):
    if i < j :
      plt.title(col_i + ' and ' + col_j)
      sns.scatterplot(data=response_rfm, x=col_i, y=col_j, hue='response',ax=axes[col])
      sns.despine()
      col = col+1

fig, axes = plt.subplots(2,5, figsize=(15, 10), sharex=True)
count =0
row = 0
for i, col_i in enumerate(response_clv[['recency', 'frequency', 'monetary_value', 'AOU', 'ticket_size']].columns):
  for j, col_j in enumerate(response_clv[['recency', 'frequency', 'monetary_value', 'AOU', 'ticket_size']].columns):
    if i < j :
      
      if count==5:
        count = 0
        row = 1
      plt.title(col_i + ' and ' + col_j)
      sns.scatterplot(data=response_clv, x=col_i, y=col_j, hue='response',ax=axes[row,count])
      sns.despine()
      count = count+1

"""# Imbalanc with SMOTE"""

sm = SMOTE(random_state=10)

sm.fit(X_train_rfm, y_train_rfm)
X_SMOTE_rfm, y_SMOTE_rfm = sm.fit_resample(X_train_rfm, y_train_rfm)
X_SMOTE_rfm = pd.DataFrame(X_SMOTE_rfm, columns=X_train_rfm.columns)


sm.fit(X_train_clv, y_train_clv)
X_SMOTE_clv, y_SMOTE_clv = sm.fit_resample(X_train_clv, y_train_clv)
X_SMOTE_clv = pd.DataFrame(X_SMOTE_clv, columns=X_train_clv.columns)


#Note Error : https://stackoverflow.com/questions/66364406/attributeerror-smote-object-has-no-attribute-fit-sample

accuracy_models = {
  "SVR RFM": 0,
  "SVR CLV": 0,
  "Logistic Regression RFM": 0,
  "Logistic Regression CLV": 0,
  "XGBoost RFM": 0,
  "XGBoost CLV": 0,
  "XGBoost Tuning": 0
}

"""# Support Vector Regression"""

from sklearn.svm import SVR
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

regr = SVR(C=1.0, epsilon=0.2)

sc_X = StandardScaler()
sc_y = StandardScaler()
X = sc_X.fit_transform(np.array(X_SMOTE_rfm))
X_test = sc_X.fit_transform(np.array(X_test_rfm))
y = sc_y.fit_transform(np.array(y_SMOTE_rfm).reshape(-1, 1))

regr.fit(X, y.ravel())

y_pred = regr.predict(X)
y_pred = sc_y.inverse_transform(y_pred) 
y_pred = np.round(y_pred)
y_pred

y_test = regr.predict(X_test)
y_test = sc_y.inverse_transform(y_test) 
y_test = np.round(y_test)
y_test

report_train = classification_report(y_SMOTE_rfm, y_pred)
print('Training Set')
print('---------------------------------------------------------')
print(report_train) 

report_test = classification_report(y_test_rfm, y_test)
report_test_dict = classification_report(y_test_rfm, y_test,output_dict=True)
print('Test Set')
print('---------------------------------------------------------')
print(report_test) 
accuracy_models['SVR RFM'] = report_test_dict['accuracy']

sc_X = StandardScaler()
sc_y = StandardScaler()
X = sc_X.fit_transform(np.array(X_SMOTE_clv))
X_test = sc_X.fit_transform(np.array(X_test_clv))
y = sc_y.fit_transform(np.array(y_SMOTE_clv).reshape(-1, 1))

regr.fit(X, y.ravel())

y_pred = regr.predict(X)
y_pred = sc_y.inverse_transform(y_pred) 
y_pred = np.round(y_pred)
y_pred

y_test = regr.predict(X_test)
y_test = sc_y.inverse_transform(y_test) 
y_test = np.round(y_test)
y_test

report_train = classification_report(y_SMOTE_clv, y_pred)
print('Training Set')
print('---------------------------------------------------------')
print(report_train) 

report_test = classification_report(y_test_clv, y_test)
report_test_dict = classification_report(y_test_clv, y_test,output_dict=True)
print('Test Set')
print('---------------------------------------------------------')
print(report_test) 
accuracy_models['SVR CLV'] = report_test_dict['accuracy']

"""# Logistic Regression"""

print('Logistic Regression SMOTE RFM')

predicted_y = []
expected_y = []

model_lr_rfm = LogisticRegression(solver='liblinear', class_weight='balanced')
model_lr_rfm = model_lr_rfm.fit(X_SMOTE_rfm, y_SMOTE_rfm)
predictions = model_lr_rfm.predict(X_SMOTE_rfm)
predicted_y.extend(predictions)
expected_y.extend(y_SMOTE_rfm)
report_train = classification_report(expected_y, predicted_y)
print('Training Set')
print('---------------------------------------------------------')
print(report_train) 

predicted_y = []
expected_y = []
predictions = model_lr_rfm.predict(X_test_rfm)
predicted_y.extend(predictions)
expected_y.extend(y_test_rfm)
report_test = classification_report(expected_y, predicted_y)
report_test_dict = classification_report(expected_y, predicted_y,output_dict=True)
print('Test Set')
print('---------------------------------------------------------')
print(report_test) 
accuracy_models['Logistic Regression RFM'] = report_test_dict['accuracy']

print('Logistic Regression SMOTE CLV')

predicted_y = []
expected_y = []

model_lr_clv = LogisticRegression(solver='liblinear', class_weight='balanced')
model_lr_clv = model_lr_clv.fit(X_SMOTE_clv, y_SMOTE_clv)
predictions = model_lr_clv.predict(X_SMOTE_clv)
predicted_y.extend(predictions)
expected_y.extend(y_SMOTE_clv)
report_train = classification_report(expected_y, predicted_y)
print('Training Set')
print('---------------------------------------------------------')
print(report_train) 

predicted_y = []
expected_y = []

predictions = model_lr_clv.predict(X_test_clv)
predicted_y.extend(predictions)
expected_y.extend(y_test_clv)
report_test = classification_report(expected_y, predicted_y)
report_test_dict = classification_report(expected_y, predicted_y,output_dict=True)
print('Test Set')
print('---------------------------------------------------------')
print(report_test) 
accuracy_models['Logistic Regression CLV'] = report_test_dict['accuracy']

"""# XGBoost"""

print('XGBoost SMOTE RFM')

xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc',
 learning_rate =0.01,
 n_estimators=100,
 max_depth=2,
 gamma=0.0,
 colsample_bytree=0.6,
 use_label_encoder=False)

X_SMOTE_rfm = X_SMOTE_rfm[['frequency', 'recency', 'monetary_value']]
X_test_rfm = X_test_rfm[['frequency', 'recency', 'monetary_value']]

xgb_model_SMOTE_rfm = xgb_model.fit(X_SMOTE_rfm, y_SMOTE_rfm, early_stopping_rounds=5, eval_set=[(X_test_rfm, y_test_rfm)])

predicted_y = []
expected_y = []

predictions =  xgb_model_SMOTE_rfm.predict(X_SMOTE_rfm)
predicted_y.extend(predictions)
expected_y.extend(y_SMOTE_rfm)
report_train = classification_report(expected_y, predicted_y)
print('Training Set')
print('---------------------------------------------------------')
print(report_train) 

predicted_y = []
expected_y = []

predictions = xgb_model_SMOTE_rfm.predict(X_test_rfm)
predicted_y.extend(predictions)
expected_y.extend(y_test_rfm)
report_test = classification_report(expected_y, predicted_y)
report_test_dict = classification_report(expected_y, predicted_y,output_dict=True)
print('Test Set')
print('---------------------------------------------------------')
print(report_test) 
accuracy_models['XGBoost RFM'] = report_test_dict['accuracy']

print('XGBoost SMOTE CLV')

xgb_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='auc',
 learning_rate =0.01,
 n_estimators=100,
 max_depth=2,
 gamma=0.0,
 colsample_bytree=0.6,
 use_label_encoder=False
                             )

xgb_model_SMOTE_clv = xgb_model.fit(X_SMOTE_clv, y_SMOTE_clv, early_stopping_rounds=5, eval_set=[(X_test_clv, y_test_clv)])

predicted_y = []
expected_y = []

predictions =  xgb_model_SMOTE_clv.predict(X_SMOTE_clv)
predicted_y.extend(predictions)
expected_y.extend(y_SMOTE_clv)
report_train = classification_report(expected_y, predicted_y)

print('Training Set')
print('---------------------------------------------------------')
print(report_train) 

predicted_y = []
expected_y = []
predictions = xgb_model_SMOTE_clv.predict(X_test_clv)
predicted_y.extend(predictions)
expected_y.extend(y_test_clv)
report_test = classification_report(expected_y, predicted_y)
report_test_dict = classification_report(expected_y, predicted_y,output_dict=True)
print('Test Set')
print('---------------------------------------------------------')
print(report_test) 
accuracy_models['XGBoost CLV'] = report_test_dict['accuracy']

"""# Hyperparameter Tuning"""

from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, chi2

pipe = Pipeline([
  ('fs', SelectKBest()),
  ('clf', xgb.XGBClassifier(objective='binary:logistic', scale_pos_weight=9, use_label_encoder=False))
])

from sklearn.model_selection import KFold, GridSearchCV
from sklearn.metrics import accuracy_score, make_scorer

search_space = [
  {
    'clf__n_estimators': [100, 300],
    'clf__learning_rate': [0.01, 0.1],
    'clf__max_depth': range(2, 5),
    'clf__colsample_bytree': [i/10.0 for i in range(4, 7)],
    'clf__gamma': [i/10.0 for i in range(3)],
    'fs__score_func': [chi2],
    'fs__k': [2],
  }
]
# Define cross validation
kfold = KFold(n_splits=5, random_state=10, shuffle=True)
# AUC and accuracy as score
scoring = {'AUC':'roc_auc', 'Accuracy':make_scorer(accuracy_score), 'F1 score': 'f1_micro'}
# Define grid search
grid = GridSearchCV(
  pipe,
  param_grid=search_space,
  cv=kfold,
  scoring=scoring,
  refit='AUC',
  verbose=1,
  n_jobs=-1
)

# Fit grid search
xgb_model_clv_GS = grid.fit(X_train_clv, y_train_clv)

predicted_y = []
expected_y = []

predictions = xgb_model_clv_GS.predict(X_test_clv)
print('Best AUC Score: {}'.format(xgb_model_clv_GS.best_score_))
print('Accuracy: {}'.format(accuracy_score(y_test_clv, predictions)))
print(confusion_matrix(y_test_clv,predictions))

predicted_y.extend(predictions)
expected_y.extend(y_test_clv)
report_test = classification_report(expected_y, predicted_y)
report_test_dict = classification_report(expected_y, predicted_y,output_dict=True)
print('Test Set')
print('---------------------------------------------------------')
print(report_test)
accuracy_models['XGBoost Tuning'] = report_test_dict['accuracy']

"""# Best Parameters"""

xgb_model_clv_GS.best_params_

"""# Best Model"""

accuracy_models

max_key = max(accuracy_models, key=accuracy_models.get)
print(max_key)